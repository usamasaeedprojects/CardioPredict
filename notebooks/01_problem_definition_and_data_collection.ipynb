{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05acb82e-33ee-4bcb-be59-64394a1daacf",
   "metadata": {},
   "source": [
    "# CardioPredict — Heart Disease Classification Using Machine Learning\n",
    "\n",
    "## Goal: \n",
    "Predict whether a patient has heart disease (binary classification).\n",
    "\n",
    "## Dataset Information\n",
    "This database contains 76 attributes, but all published experiments refer to using a subset of 14 of them.  In particular, the Cleveland database is the only one that has been used by ML researchers to date.  The \"goal\" field refers to the presence of heart disease in the patient.  It is integer valued from 0 (no presence) to 4. Experiments with the Cleveland database have concentrated on simply attempting to distinguish presence (values 1,2,3,4) from absence (value 0).  \n",
    "   \n",
    "The names and social security numbers of the patients were recently removed from the database, replaced with dummy values.\n",
    "\n",
    "One file has been \"processed\", that one containing the Cleveland database.  All four unprocessed files also exist in this directory.\n",
    "\n",
    "To see Test Costs (donated by Peter Turney), please see the folder \"Costs\" \n",
    "\n",
    "**Reference:** https://archive.ics.uci.edu/dataset/45/heart+disease"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deaccd3d-e8c0-4f5b-9911-5de4d84b5fe2",
   "metadata": {},
   "source": [
    "## Additional Variable Information\n",
    "\n",
    "Only 14 attributes used:\n",
    "\n",
    "      1. #3  (age)       \n",
    "      2. #4  (sex)       \n",
    "      3. #9  (cp)        \n",
    "      4. #10 (trestbps)  \n",
    "      5. #12 (chol)      \n",
    "      6. #16 (fbs)       \n",
    "      7. #19 (restecg)   \n",
    "      8. #32 (thalach)   \n",
    "      9. #38 (exang)     \n",
    "      10. #40 (oldpeak)   \n",
    "      11. #41 (slope)     \n",
    "      12. #44 (ca)        \n",
    "      13. #51 (thal)      \n",
    "      14. #58 (num)       (the predicted attribute)\n",
    "\n",
    "Complete attribute documentation:\n",
    "\n",
    "      1 id: patient identification number\n",
    "      2 ccf: social security number (I replaced this with a dummy value of 0)\n",
    "      3 age: age in years\n",
    "      4 sex: sex (1 = male; 0 = female)\n",
    "      5 painloc: chest pain location (1 = substernal; 0 = otherwise)\n",
    "      6 painexer (1 = provoked by exertion; 0 = otherwise)\n",
    "      7 relrest (1 = relieved after rest; 0 = otherwise)\n",
    "      8 pncaden (sum of 5, 6, and 7)\n",
    "      9 cp: chest pain type\n",
    "        -- Value 1: typical angina\n",
    "        -- Value 2: atypical angina\n",
    "        -- Value 3: non-anginal pain\n",
    "        -- Value 4: asymptomatic\n",
    "     10 trestbps: resting blood pressure (in mm Hg on admission to the hospital)\n",
    "     11 htn\n",
    "     12 chol: serum cholestoral in mg/dl\n",
    "     13 smoke: I believe this is 1 = yes; 0 = no (is or is not a smoker)\n",
    "     14 cigs (cigarettes per day)\n",
    "     15 years (number of years as a smoker)\n",
    "     16 fbs: (fasting blood sugar > 120 mg/dl)  (1 = true; 0 = false)\n",
    "     17 dm (1 = history of diabetes; 0 = no such history)\n",
    "     18 famhist: family history of coronary artery disease (1 = yes; 0 = no)\n",
    "     19 restecg: resting electrocardiographic results\n",
    "        -- Value 0: normal\n",
    "        -- Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)\n",
    "        -- Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria\n",
    "     20 ekgmo (month of exercise ECG reading)\n",
    "     21 ekgday(day of exercise ECG reading)\n",
    "     22 ekgyr (year of exercise ECG reading)\n",
    "     23 dig (digitalis used furing exercise ECG: 1 = yes; 0 = no)\n",
    "     24 prop (Beta blocker used during exercise ECG: 1 = yes; 0 = no)\n",
    "     25 nitr (nitrates used during exercise ECG: 1 = yes; 0 = no)\n",
    "     26 pro (calcium channel blocker used during exercise ECG: 1 = yes; 0 = no)\n",
    "     27 diuretic (diuretic used used during exercise ECG: 1 = yes; 0 = no)\n",
    "     28 proto: exercise protocol\n",
    "          1 = Bruce     \n",
    "          2 = Kottus\n",
    "          3 = McHenry\n",
    "          4 = fast Balke\n",
    "          5 = Balke\n",
    "          6 = Noughton \n",
    "          7 = bike 150 kpa min/min  (Not sure if \"kpa min/min\" is what was written!)\n",
    "          8 = bike 125 kpa min/min  \n",
    "          9 = bike 100 kpa min/min\n",
    "         10 = bike 75 kpa min/min\n",
    "         11 = bike 50 kpa min/min\n",
    "         12 = arm ergometer\n",
    "     29 thaldur: duration of exercise test in minutes\n",
    "     30 thaltime: time when ST measure depression was noted\n",
    "     31 met: mets achieved\n",
    "     32 thalach: maximum heart rate achieved\n",
    "     33 thalrest: resting heart rate\n",
    "     34 tpeakbps: peak exercise blood pressure (first of 2 parts)\n",
    "     35 tpeakbpd: peak exercise blood pressure (second of 2 parts)\n",
    "     36 dummy\n",
    "     37 trestbpd: resting blood pressure\n",
    "     38 exang: exercise induced angina (1 = yes; 0 = no)\n",
    "     39 xhypo: (1 = yes; 0 = no)\n",
    "     40 oldpeak = ST depression induced by exercise relative to rest\n",
    "     41 slope: the slope of the peak exercise ST segment\n",
    "        -- Value 1: upsloping\n",
    "        -- Value 2: flat\n",
    "        -- Value 3: downsloping\n",
    "     42 rldv5: height at rest\n",
    "     43 rldv5e: height at peak exercise\n",
    "     44 ca: number of major vessels (0-3) colored by flourosopy\n",
    "     45 restckm: irrelevant\n",
    "     46 exerckm: irrelevant\n",
    "     47 restef: rest raidonuclid (sp?) ejection fraction\n",
    "     48 restwm: rest wall (sp?) motion abnormality\n",
    "        0 = none\n",
    "        1 = mild or moderate\n",
    "        2 = moderate or severe\n",
    "        3 = akinesis or dyskmem (sp?)\n",
    "     49 exeref: exercise radinalid (sp?) ejection fraction\n",
    "     50 exerwm: exercise wall (sp?) motion \n",
    "     51 thal: 3 = normal; 6 = fixed defect; 7 = reversable defect\n",
    "     52 thalsev: not used\n",
    "     53 thalpul: not used\n",
    "     54 earlobe: not used\n",
    "     55 cmo: month of cardiac cath (sp?)  (perhaps \"call\")\n",
    "     56 cday: day of cardiac cath (sp?)\n",
    "     57 cyr: year of cardiac cath (sp?)\n",
    "     58 num: diagnosis of heart disease (angiographic disease status)\n",
    "        -- Value 0: < 50% diameter narrowing\n",
    "        -- Value 1: > 50% diameter narrowing\n",
    "        (in any major vessel: attributes 59 through 68 are vessels)\n",
    "     59 lmt\n",
    "     60 ladprox\n",
    "     61 laddist\n",
    "     62 diag\n",
    "     63 cxmain\n",
    "     64 ramus\n",
    "     65 om1\n",
    "     66 om2\n",
    "     67 rcaprox\n",
    "     68 rcadist\n",
    "     69 lvx1: not used\n",
    "     70 lvx2: not used\n",
    "     71 lvx3: not used\n",
    "     72 lvx4: not used\n",
    "     73 lvf: not used\n",
    "     74 cathef: not used\n",
    "     75 junk: not used\n",
    "     76 name: last name of patient  (I replaced this with the dummy string \"name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "738a24f7-d034-4fa5-a15f-8f4e10a66456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "17db7a1e-0216-42d5-9944-784bcb9f17ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to convert .data into .csv\n",
    "def convert_into_csv(file, load_path, save_path, columns):\n",
    "    # 1. Load the file\n",
    "    df = pd.read_csv(load_path + file + '.data', header=None)\n",
    "\n",
    "    # 2. Assign column names\n",
    "    df.columns = columns\n",
    "\n",
    "    # 3. Replace '?' with NaN\n",
    "    df = df.replace('?', pd.NA)\n",
    "\n",
    "    # 4. Save as clean CSV\n",
    "    df.to_csv(save_path + file + '.csv', index=False)\n",
    "\n",
    "    print('Converted to CSV successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "06950968-41d1-4a36-b910-b6b4650d75a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted to CSV successfully\n"
     ]
    }
   ],
   "source": [
    "# Column names\n",
    "columns = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target']\n",
    "# Files to convert into CSV\n",
    "file = ['processed.cleveland', \n",
    "        'processed.hungarian', \n",
    "        'processed.switzerland', \n",
    "        'processed.va']\n",
    "# Path to load a file\n",
    "load_path = '../data/raw/heart+disease/'\n",
    "# Path to save a file\n",
    "save_path = '../data/processed/'\n",
    "# Calling function to convert *.data into *.csv\n",
    "convert_into_csv(file[3], load_path, save_path, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1fbfe20f-bd28-4610-8ce9-4083b7a2b8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataset created with 920 rows and 15 columns.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>cleveland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>cleveland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>cleveland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>cleveland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>cleveland</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0  63.0  1.0  1.0     145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
       "1  67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
       "2  67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
       "3  37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
       "4  41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
       "\n",
       "   slope   ca  thal  target     source  \n",
       "0    3.0  0.0   6.0       0  cleveland  \n",
       "1    2.0  3.0   3.0       2  cleveland  \n",
       "2    2.0  2.0   7.0       1  cleveland  \n",
       "3    3.0  0.0   3.0       0  cleveland  \n",
       "4    1.0  0.0   3.0       0  cleveland  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge all four datasets into a single dataset\n",
    "path = '../data/processed/'\n",
    "files = ['processed.cleveland.csv',\n",
    "        'processed.hungarian.csv',\n",
    "        'processed.switzerland.csv',\n",
    "        'processed.va.csv']\n",
    "datasets = []\n",
    "\n",
    "for file in files:\n",
    "    file_path = path + file\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['source'] = file.replace('processed.', '').replace('.csv','') # add source column\n",
    "    datasets.append(df)\n",
    "\n",
    "# Concatenate all into one dataframe\n",
    "heart_combined = pd.concat(datasets, ignore_index=True)\n",
    "\n",
    "# Save merged dataset\n",
    "output_path = '../data/processed/heart_disease_combined.csv'\n",
    "heart_combined.to_csv(output_path, index=False)\n",
    "\n",
    "# Display shape and sample\n",
    "print(f'Combined dataset created with {heart_combined.shape[0]} rows and {heart_combined.shape[1]} columns.')\n",
    "heart_combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48885ae-4537-4b8d-972d-10d2605a218d",
   "metadata": {},
   "source": [
    "### Data Selection Summary\n",
    "\n",
    "Based on the UCI Heart Disease dataset documentation, only four primary processed files were used for this analysis:\n",
    "\n",
    "- `processed.cleveland.data`\n",
    "- `processed.hungarian.data`\n",
    "- `processed.switzerland.data`\n",
    "- `processed.va.data`\n",
    "\n",
    "All other available files were **discarded** because they contain inconsistent schemas, unknown column definitions, or incomplete records.  \n",
    "Including them could introduce **schema inconsistencies**, **uninterpretable variables**, and potential **data integrity issues** into the analysis.\n",
    "\n",
    "Therefore, only the four officially documented processed datasets were retained for further cleaning, exploration, and modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d5fabcb7-7e50-4bb0-93f3-1fdb50c84289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (920, 15)\n",
      "\n",
      "Columns :  ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target', 'source']\n",
      "\n",
      "Missing data :  age           0\n",
      "sex           0\n",
      "cp            0\n",
      "trestbps     59\n",
      "chol         30\n",
      "fbs          90\n",
      "restecg       2\n",
      "thalach      55\n",
      "exang        55\n",
      "oldpeak      62\n",
      "slope       309\n",
      "ca          611\n",
      "thal        486\n",
      "target        0\n",
      "source        0\n",
      "dtype: int64\n",
      "\n",
      "Target distribution:  target\n",
      "0    411\n",
      "1    265\n",
      "2    109\n",
      "3    107\n",
      "4     28\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Confirm that the merged dataset is valid and ready for EDA\n",
    "df = pd.read_csv('../data/processed/heart_disease_combined.csv')\n",
    "\n",
    "# Check shape\n",
    "print('Shape: ', df.shape)\n",
    "\n",
    "# Check column consistency\n",
    "print('\\nColumns : ', df.columns.tolist())\n",
    "\n",
    "# Check for missing data\n",
    "print('\\nMissing data : ', df.isna().sum())\n",
    "\n",
    "# Quick look at unique target values\n",
    "print('\\nTarget distribution: ', df['target'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fc0f53-16ea-4b7f-a523-d42543b4cc25",
   "metadata": {},
   "source": [
    "### Data Collection Summary\n",
    "\n",
    "- **Source:** UCI Machine Learning Repository – Heart Disease Dataset  \n",
    "- **Files Used:** Cleveland, Hungarian, Switzerland, and VA  \n",
    "- **Total Records (after merge):** <insert number after verifying>  \n",
    "- **Total Features:** 14 attributes + 1 source identifier  \n",
    "- **Excluded Files:** `new.data` and others with inconsistent schemas  \n",
    "- **File Saved As:** `data/processed/heart_disease_combined.csv`\n",
    "\n",
    "Data collection and preparation are complete.  \n",
    "The next step involves **data cleaning and exploratory data analysis (EDA)**.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
